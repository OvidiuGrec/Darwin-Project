[general]
# Sets the name of the experiment for mlflow:
experiment: baseline
# Seed for reproducibility
seed: 999
# Choose which data to use:
# Options: audio, video, combined
feature_type: combined
# When to fuse the results
# Options: early - fuse at feature level and then perform scaling and dimensionality reduction
#          mid - preprocess features individually and then fuse two final feature vectors
#          late - make predictions using individual features and then fuse them at the end
fusion: early
# value required for predictions over bimodal mode
# i.e. where (feature_type = combined) and (fusion = late)
prediction_weights: 0.5+0.5

[audio]
# Audio features to use
# Options: AVEC, XCORR, EGEMAPS
audio_features: AVEC
model_name: PLS+LR
model_weights: 0.5+0.5

# TODO: add options for different scaling

[video]
# Video features to use (add FD at the end to use fdhh)
# Options: VGG_32_(FD) - 32nd fully connected layer from standard VGGFace architecture
#          RES_AVGPOOL_(FD) - last avgpool layer from RESNET architecture
video_features: VGG_32_FD
model_name: PLS+LR
model_weights: 0.5+0.5

# Parameters for early/mid fusion:
[combined]
# Names for the models split by a + sign (e.g: PLS+LR):
# Options: LR, PLS, FNN
model_name: PLS+LR
# Weights for the models, should add up to 1 (e.g: 0.5+0.5):
model_weights: 0.5+0.5

[folders]
# Raw video file location:
raw_video_folder: D:\Education\University\Darwin-Project\data\video\Video
# Face coordinate files:
facial_data: data\video\faces
# Extracted features location:
video_folder: data\video\features
# Raw audio file locations
raw_audio_folder: data\audio\raw
seg_audio_folder: data\audio\segments
audio_folder: data\audio\features
# Labels folder:
labels_folder: data\labels\AVEC2014_Labels
# Location of models:
models_folder: models


