[general]
# Sets the name of the experiment for mlflow:
experiment: fnn_combined
# Seed for reproducibility
seed: 2020
# Choose which data to use:
# Options: audio, video, combined
feature_type: combined
# Audio features to use
# Options: AVEC          - all AVEC2014 baseline features extracted using OpenSmile
#          XCORR         - a series of cross correlated features as explained in Williamson's paper
#          XCORR_TOOLKIT - a series of cross correlated features as explained in Williamson's paper,
#                          but extracted using Praat and openSMILE toolkits
#          EGEMAPS       - features extracted using the egemaps config provided by OpenSmile
#          EGEMAPS_3     - averaged egemaps features over 3 second segmenting
#          MFCC          - subset of AVEC features containing only mfcc coefficients
audio_features: mfcc
# Video features to use (add FD at the end to use fdhh)
# Options: VGG_32_(FD) - 32nd fully connected layer from standard VGGFace architecture
#          RES_AVGPOOL_(FD) - last avgpool layer from RESNET architecture
#          SE_AVGPOOL_(FD) - last avgpool layer from SENET architecture
video_features: SE_AVGPOOL_FD

# Parameters for early/mid fusion:
[combined]
# Names for the models split by a (+) sign (e.g: PLS+LR):
# Options: LR, PLS, FNN
combined_model: FNN+PLS
# Weights for the models, should add up to 1 (e.g: 0.5+0.5):
combined_model_weights: 0.5+0.5
# When to fuse the results
# Options: early - fuse at feature level and then perform scaling and dimensionality reduction
#          mid - preprocess features individually and then fuse two final feature vectors
#          late - make predictions using individual features and then fuse them at the end
fusion: mid
# Define how  data should be scaled during preprocessing
# Options: standard - uses StandardScaler from sklearn
#          minmax - uses MinMaxScaler from sklearn
#          boxcox - optionally add with a (+) sign to transform long-tail distribution
combined_scaler: minmax
# Options: 0 - scale column-wise (used if features are not related)
#          1 - scale row-wise
#          None (default if left empty) - scale all features at once (used if feature represent same thing (e.g: pixels)
combined_scale_axis: 0
# value required for predictions over bimodal mode
# i.e. where (feature_type = combined) and (fusion = late)
prediction_weights: 0.5+0.5

[audio]
audio_model: PLS
audio_model_weights: 1
audio_scaler: minmax
audio_scale_axis: 0

[video]
video_model: LR
video_model_weights: 1
video_scaler: boxcox+standard
video_scale_axis: 0+0

[folders]
# Raw video file location:
raw_video_folder: C:\Darwin-Project\data\video\Video
# Face coordinate files:
facial_data: data\video\faces
# Extracted features location:
video_folder: data\video\features
# Raw audio file locations
raw_audio_folder: data\audio\raw
seg_audio_folder: data\audio\segments
audio_folder: data\audio\features
# Raw toolkit audio features location
raw_audio_toolkit_folder: C:\Features\praat_opensmile_features
# Labels folder:
labels_folder: data\labels\AVEC2014_Labels
# Location of models:
models_folder: models


